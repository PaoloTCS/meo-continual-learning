# MEO: Mask Evolution Operators for Continual Learning Stability

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![arXiv](https://img.shields.io/badge/arXiv-XXXX.XXXXX-b31b1b.svg)](https://arxiv.org/abs/XXXX.XXXXX)

This repository contains the implementation of **Mask Evolution Operators (MEOs)**, a lightweight activation-level mechanism that applies adaptive masks as a restoring force to stabilize internal representations during continual learning.

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/PaoloTCS/meo-continual-learning.git
cd meo-continual-learning

# Install dependencies
pip install -r requirements.txt

# Run training
python src/train.py --config configs/meo_cifar100.yaml
```

## ğŸ“– Overview

MEOs provide a complementary **activation-space** mechanism to weight-based methods for continual learning. They directly damp harmful representation drift while allowing principled evolution through:

- **Adaptive activation masks** that exert restoring forces toward references
- **Evolution operators** (identity/EMA/subspace) for controlled plasticity
- **Open- vs. closed-loop** timing strategies
- **Drift metrics** for stability monitoring

## ğŸ—ï¸ Repository Structure

```
meo-continual-learning/
â”œâ”€ paper/                    # Research paper and assets
â”‚  â”œâ”€ MEO_Paper_v2_clean.tex
â”‚  â”œâ”€ MEO_Paper_v2_clean.pdf
â”‚  â”œâ”€ drift_placeholder.png
â”‚  â””â”€ alpha_sweep_placeholder.png
â”œâ”€ src/                      # Source code
â”‚  â”œâ”€ meo.py                # Mask evolution operators
â”‚  â”œâ”€ ewc.py                # EWC implementation
â”‚  â”œâ”€ data.py               # CIFAR-100 data loading
â”‚  â””â”€ train.py              # Training entrypoints
â”œâ”€ configs/                  # Configuration files
â”‚  â”œâ”€ meo_cifar100.yaml
â”‚  â””â”€ ewc_cifar100.yaml
â”œâ”€ results/                  # Outputs (gitignored)
â”‚  â”œâ”€ logs/                 # Training logs
â”‚  â””â”€ figures/              # Generated plots
â””â”€ docs/                     # Documentation
```

## ğŸ”¬ Key Results

On a 10-task split of CIFAR-100 with ResNet-50:

| Method | Final Accuracy | Drift Metric |
|--------|----------------|--------------|
| Finetune | 51.2% | High |
| EWC (tuned) | 62.0% | Medium |
| **MEO (identity)** | **69.1%** | **Near-zero** |

## ğŸ“š Paper

The research paper is available in the `paper/` directory:
- **LaTeX source**: `MEO_Paper_v2_clean.tex`
- **Compiled PDF**: `MEO_Paper_v2_clean.pdf`

## ğŸ› ï¸ Implementation

### Core Components

- **`meo.py`**: Implementation of mask evolution operators
- **`ewc.py`**: Elastic Weight Consolidation baseline
- **`data.py`**: CIFAR-100 data loading and task splitting
- **`train.py`**: Training loops and evaluation

### Configuration

YAML configuration files control hyperparameters:
- Learning rates and schedules
- MEO stiffness parameters (Î±)
- Evolution operator selection
- Training protocols

## ğŸ“Š Usage Examples

```python
from src.meo import MEO
from src.data import CIFAR100Continual

# Initialize MEO with identity evolution
meo = MEO(evolution_type='identity', alpha=0.1)

# Train on continual learning tasks
for task_id in range(10):
    task_data = continual_data.get_task(task_id)
    meo.train_on_task(task_data)
```

## ğŸ”§ Dependencies

- Python 3.8+
- PyTorch 1.9+
- torchvision
- numpy
- matplotlib
- pyyaml

## ğŸ“„ License

- **Code**: MIT License (see [LICENSE](LICENSE))
- **Paper**: CC BY 4.0

## ğŸ¤ Citation

If you use this work, please cite:

```bibtex
@software{meo_continual_learning,
  title={MEO: Mask Evolution Operators for Continual Learning Stability},
  author={Pignatelli di Montecalvo, Paolo},
  year={2025},
  url={https://github.com/PaoloTCS/meo-continual-learning}
}
```

## ğŸ“ Contact

- **Author**: Paolo Pignatelli di Montecalvo
- **Email**: [Your Email]
- **Affiliation**: Independent Researcher; Verbum Technologies

## ğŸ™ Acknowledgments

Thanks to the continual learning research community and contributors to this project.

---

**Note**: This is a research implementation. For production use, additional testing and validation is recommended.
